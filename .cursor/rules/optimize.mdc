# Role

- You will receives a number of solutions to create.
- Do one iteration in the optimization loop at a time.
- You can see the ranking of previous solutions.
- Implement a solution that is both novel and introduces the most impactful yet simplest idea.
- Novel, impactful and simple.
- You can build on top of previous solutions.
- We are gradually exploring the space of solutions. So trying one simple idea at a time, helps us identify what actually makes a difference.
- We want to minimize the metric, but after that, we want to minimize complexity.


# Workflow

- Start by checking the current ranking: `uv run src/visualization.py`
- Read the solutions that might interest you at: `src/solutions/`
- Think deeply about other solutions that could be novel, impactful and simple.

- For each solution:
    - Create a script `src/solutions/solution_name.py`
    - In that script, at least one function must be called `solution_name`, it will be the entry point for the evaluator.
    - After you complete a solution, you MUST evaluate it with `uv run src/evaluation.py solution_name`
    - You will get a notion of how well it does and if there are any errors


# Solution

- The `solution_name` function:
    - The input is a loss curve, a list of pairs (step, loss)
    - The curve is monotonically decreasing because it is actually the cumulative minimum loss.
    - Steps and loss are already converted to log-log space.
    - Points on the curve have been subsampled to be uniform in log-space.
    - The curve is incomplete - it does not contain the last part of the training.
    - Here is a dummy example:

```python
def dummy(curve: list[float, float]) -> callable:
    """
    This is a dummy function.
    Params should be determined based on the incomplete `curve`.
    Functions should contain a concise docstring.
    """
    param_a, param_b = random.random(), random.random()
    def loss(step: float) -> float:
        return step * param_b + param_a
    return loss
```


# Evaluation

- We are trying to model the last stage of training, where the loss converges in a predictable way.
- The function you will make models the first derivative of the loss once it starts converging.
- The function will be used to extrapolate the rest of the training.
- The function will be evaluated by how early can it correctly predict the final loss within a certain error.
- The function will be run on several curves, the final evaluation metric is the average step of early stop.  
- The sooner, the better. That is we want to minimize the average step.

