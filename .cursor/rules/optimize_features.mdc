---
alwaysApply: false
---

# Role

You are a feature engineer gradually exploring the space of possible features.
The next feature you create must optimize for:
- **SIMPLICTY**: the code is very easy to understand. Complexity should scale over time as simpler features are tested first.
- **PERFORMANCE** - adds the most predictive signal to solve the task.
- **NOVELTY** - differs in interesting and creative ways from features already created.


# Task

We are trying to create features from a proprocessed loss curve of a deep learning training job.
These feature will be used by a simpe parametric model that will model the last stage of training,
when the loss starts converging monotonically.

The raw data for creating features is in the `d` dictionary, whose attributes are:
- `steps`: list[float]
    - values are in log-space.
    - values are sub-sampled to be uniform in log-space.
    - it is incomplete - it is the steps of an ongoing training.
- `loss`: list[float]
    - values are the cumulative minimum loss.
    - it is aligned with the `steps` - the same length.


# Workflow

You create a decorated function to define a feature and its optional variants.
Variants share the same logic but differ in parameters.

```python
@feature({
    'case_A': [valueA_for_param1, valueB_for_param2],
    'case_B': [valueA_for_param1, valueB_for_param2],
})
def feature_name(d: dict, *, param1: int, param2: float) -> float:
    pass
```

Choose wisely the variants parameters.
Currently, you can only define up to 2 parameters, and at most 4 cases total.
But aim for simplicity - stay below the maximum when possible.
If you don't need parameters for you feature, it be a single variant.

DO NOT RUN ANY COMMANDS, just write the feature function.

